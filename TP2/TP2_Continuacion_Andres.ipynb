{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## IMPORTACIÓN GENERAL DE LIBRERIAS Y VISUALIZACIÓN DE DATOS (matplotlib y seaborn)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as DT\n",
    "import warnings as wr\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "## from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default') \n",
    "sns.set(style=\"whitegrid\") \n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## EVENTS.\n",
    "################################################################\n",
    "## OBTENEMOS TODA LA INFORMACIÓN DE LOS DIFERENTES CSV.\n",
    "events = pd.read_csv('../../events.csv')\n",
    "## TRANSFORMACIÓN DE TIPOS PARA EL CSV (EVENTS)\n",
    "events['wifi'] = events['wifi'].fillna(False).astype(bool)\n",
    "events['connection_type'] = events['connection_type'].astype('category')\n",
    "events['trans_id'] = events['trans_id'].astype('category')\n",
    "events['date'] = pd.to_datetime(events['date'], infer_datetime_format=True)\n",
    "## DIFERENCIAMOS EN TRES COLUMNAS DIFERENTES EL DIA, MES Y AÑO.\n",
    "events['mes'] = events['date'].dt.month\n",
    "events['dia'] = events['date'].dt.day\n",
    "events['hora'] = events['date'].dt.hour\n",
    "# ARMAMOS UNA LÓGICA PARA SEGMENTAR LAS FRANJAS HORARIAS.\n",
    "# MADRUGADA de 00 a 06\n",
    "events['hora_madrugada'] = 0\n",
    "events.loc[((events.hora > -1) & (events.hora < 7)), 'hora_madrugada'] = 1\n",
    "# MAÑANA de 07 a 11\n",
    "events['hora_maniana'] = 0\n",
    "events.loc[((events.hora > 6) & (events.hora < 12)), 'hora_maniana'] = 1\n",
    "# ALMUERZO de 12 a 13\n",
    "events['hora_almuerzo'] = 0\n",
    "events.loc[((events.hora > 11) & (events.hora < 14)), 'hora_almuerzo'] = 1\n",
    "# TARDE de 14 a 18\n",
    "events['hora_tarde'] = 0\n",
    "events.loc[((events.hora > 13) & (events.hora < 19)), 'hora_tarde'] = 1\n",
    "# NOCHE de 19 a 23\n",
    "events['hora_noche'] = 0\n",
    "events.loc[((events.hora > 18) & (events.hora < 24)), 'hora_noche'] = 1\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### connection_type\n",
    "dummies = pd.get_dummies(events['connection_type'], drop_first=False)\n",
    "events = pd.concat([events, dummies], axis=1)\n",
    "del events['connection_type']\n",
    "##################### event_uuid\n",
    "del events['event_uuid']\n",
    "##################### date\n",
    "del events['date']\n",
    "##################### wifi\n",
    "events['wifi_value'] = 2\n",
    "events.loc[events.wifi == False, 'wifi_value'] = 0\n",
    "events.loc[events.wifi == True, 'wifi_value'] = 1\n",
    "del events['wifi']\n",
    "##################### attributed\n",
    "events['attributed_value'] = 2\n",
    "events.loc[events.attributed == False, 'attributed_value'] = 0\n",
    "events.loc[events.attributed == True, 'attributed_value'] = 1\n",
    "del events['attributed']\n",
    "##################### trans_id\n",
    "events['trans_id_value'] = events['trans_id'].cat.codes\n",
    "events.loc[events.trans_id_value == -1, 'trans_id_value'] = 0\n",
    "del events['trans_id']\n",
    "##################### fillna\n",
    "events.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Ventana 1: Del 18 al 20\n",
    "## Ventana 2: Del 19 al 21\n",
    "## Ventana 3: Del 20 al 22\n",
    "## Ventana 4: Del 21 al 23\n",
    "## Ventana 5: Del 22 al 24\n",
    "################################################################\n",
    "events_Ventana1 = events[(events['dia'] >= 21) & (events['dia'] <= 23)]\n",
    "events_Ventana2 = events[(events['dia'] >= 24) & (events['dia'] <= 26)]\n",
    "#events_Ventana3 = events[(events['dia'] >= 20) & (events['dia'] <= 22)]\n",
    "#events_Ventana4 = events[(events['dia'] >= 21) & (events['dia'] <= 23)]\n",
    "#events_Ventana5 = events[(events['dia'] >= 22) & (events['dia'] <= 24)]\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Limpiamos el CSV cargado para que no ocupe memoria.\n",
    "## events = ''\n",
    "## events_Ventana1 = ''\n",
    "## events_Ventana2 = ''\n",
    "## events_Ventana3 = ''\n",
    "## events_Ventana4 = ''\n",
    "## events_Ventana5 = ''\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## CLICKS.\n",
    "################################################################\n",
    "## OBTENEMOS TODA LA INFORMACIÓN DE LOS DIFERENTES CSV.\n",
    "clicks = pd.read_csv('../../clicks.csv')\n",
    "## TRANSFORMACIÓN DE TIPOS PARA EL CSV (CLICKS)\n",
    "clicks['created'] = pd.to_datetime(clicks['created'], infer_datetime_format=True)\n",
    "## DIFERENCIAMOS EN TRES COLUMNAS DIFERENTES EL DIA, MES Y AÑO.\n",
    "clicks['mes'] = clicks['created'].dt.month\n",
    "clicks['dia'] = clicks['created'].dt.day\n",
    "clicks['hora'] = clicks['created'].dt.hour\n",
    "# ARMAMOS UNA LÓGICA PARA SEGMENTAR LAS FRANJAS HORARIAS.\n",
    "# MADRUGADA de 00 a 06\n",
    "clicks['hora_madrugada'] = 0\n",
    "clicks.loc[((clicks.hora > -1) & (clicks.hora < 7)), 'hora_madrugada'] = 1\n",
    "# MAÑANA de 07 a 11\n",
    "clicks['hora_maniana'] = 0\n",
    "clicks.loc[((clicks.hora > 6) & (clicks.hora < 12)), 'hora_maniana'] = 1\n",
    "# ALMUERZO de 12 a 13\n",
    "clicks['hora_almuerzo'] = 0\n",
    "clicks.loc[((clicks.hora > 11) & (clicks.hora < 14)), 'hora_almuerzo'] = 1\n",
    "# TARDE de 14 a 18\n",
    "clicks['hora_tarde'] = 0\n",
    "clicks.loc[((clicks.hora > 13) & (clicks.hora < 19)), 'hora_tarde'] = 1\n",
    "# NOCHE de 19 a 23\n",
    "clicks['hora_noche'] = 0\n",
    "clicks.loc[((clicks.hora > 18) & (clicks.hora < 24)), 'hora_noche'] = 1\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### trans_id\n",
    "clicks.fillna(0, inplace = True)\n",
    "clicks['trans_id'] = clicks['trans_id'].astype('category')\n",
    "##################### date\n",
    "del clicks['created']\n",
    "##################### wifi_connection\n",
    "clicks['wifi_value'] = 2\n",
    "clicks.loc[clicks.wifi_connection == False, 'wifi_value'] = 0\n",
    "clicks.loc[clicks.wifi_connection == True, 'wifi_value'] = 1\n",
    "del clicks['wifi_connection']\n",
    "##################### trans_id\n",
    "clicks['trans_id_value'] = clicks['trans_id'].cat.codes\n",
    "clicks.loc[clicks.trans_id_value == -1, 'trans_id_value'] = 0\n",
    "del clicks['trans_id']\n",
    "##################### touchXY\n",
    "clicks.loc[clicks.touchX == 'Infinity', 'touchX'] = 2\n",
    "clicks.loc[clicks.touchY == 'Infinity', 'touchY'] = 2\n",
    "clicks['touchX'] = clicks['touchX'].astype(float).fillna(0.0)\n",
    "clicks['touchY'] = clicks['touchY'].astype(float).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Ventana 1: Del 18 al 20\n",
    "## Ventana 2: Del 19 al 21\n",
    "## Ventana 3: Del 20 al 22\n",
    "## Ventana 4: Del 21 al 23\n",
    "## Ventana 5: Del 22 al 24\n",
    "################################################################\n",
    "clicks_Ventana1 = clicks[(clicks['dia'] >= 21) & (clicks['dia'] <= 23)]\n",
    "clicks_Ventana2 = clicks[(clicks['dia'] >= 24) & (clicks['dia'] <= 26)]\n",
    "#clicks_Ventana3 = clicks[(clicks['dia'] >= 20) & (clicks['dia'] <= 22)]\n",
    "#clicks_Ventana4 = clicks[(clicks['dia'] >= 21) & (clicks['dia'] <= 23)]\n",
    "#clicks_Ventana5 = clicks[(clicks['dia'] >= 22) & (clicks['dia'] <= 24)]\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Limpiamos el CSV cargado para que no ocupe memoria.\n",
    "## clicks = ''\n",
    "## clicks_Ventana1 = ''\n",
    "## clicks_Ventana2 = ''\n",
    "## clicks_Ventana3 = ''\n",
    "## clicks_Ventana4 = ''\n",
    "## clicks_Ventana5 = ''\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## INSTALLS.\n",
    "################################################################\n",
    "## OBTENEMOS TODA LA INFORMACIÓN DE LOS DIFERENTES CSV.\n",
    "installs = pd.read_csv('../../installs.csv')\n",
    "## TRANSFORMACIÓN DE TIPOS PARA EL CSV (INSTALLS)\n",
    "installs['kind'] = installs['kind'].astype('category')\n",
    "installs['user_agent'] = installs['user_agent'].astype('category')\n",
    "installs['session_user_agent'] = installs['session_user_agent'].astype('category')\n",
    "installs['created'] = pd.to_datetime(installs['created'], infer_datetime_format=True)\n",
    "installs['trans_id'] = installs['trans_id'].astype('category')\n",
    "## DIFERENCIAMOS EN TRES COLUMNAS DIFERENTES EL DIA, MES Y AÑO.\n",
    "installs['mes'] = installs['created'].dt.month\n",
    "installs['dia'] = installs['created'].dt.day\n",
    "installs['hora'] = installs['created'].dt.hour\n",
    "# ARMAMOS UNA LÓGICA PARA SEGMENTAR LAS FRANJAS HORARIAS.\n",
    "# MADRUGADA de 00 a 06\n",
    "installs['hora_madrugada'] = 0\n",
    "installs.loc[((installs.hora > -1) & (installs.hora < 7)), 'hora_madrugada'] = 1\n",
    "# MAÑANA de 07 a 11\n",
    "installs['hora_maniana'] = 0\n",
    "installs.loc[((installs.hora > 6) & (installs.hora < 12)), 'hora_maniana'] = 1\n",
    "# ALMUERZO de 12 a 13\n",
    "installs['hora_almuerzo'] = 0\n",
    "installs.loc[((installs.hora > 11) & (installs.hora < 14)), 'hora_almuerzo'] = 1\n",
    "# TARDE de 14 a 18\n",
    "installs['hora_tarde'] = 0\n",
    "installs.loc[((installs.hora > 13) & (installs.hora < 19)), 'hora_tarde'] = 1\n",
    "# NOCHE de 19 a 23\n",
    "installs['hora_noche'] = 0\n",
    "installs.loc[((installs.hora > 18) & (installs.hora < 24)), 'hora_noche'] = 1\n",
    "#installs['cantidad'] = 1\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### fillna\n",
    "installs['click_hash'].fillna(0, inplace = True)\n",
    "installs['device_brand'].fillna(0, inplace = True)\n",
    "installs['device_model'].fillna(0, inplace = True)\n",
    "installs['device_language'].fillna(0, inplace = True)\n",
    "##################### created event\n",
    "del installs['event_uuid']\n",
    "#del installs['created']\n",
    "##################### wifi\n",
    "installs['wifi_value'] = 2\n",
    "installs.loc[installs.wifi == False, 'wifi_value'] = 0\n",
    "installs.loc[installs.wifi == True, 'wifi_value'] = 1\n",
    "del installs['wifi']\n",
    "##################### attributed\n",
    "installs['attributed_value'] = 2\n",
    "installs.loc[installs.attributed == False, 'attributed_value'] = 0\n",
    "installs.loc[installs.attributed == True, 'attributed_value'] = 1\n",
    "del installs['attributed']\n",
    "##################### implicit\n",
    "installs['implicit_value'] = 2\n",
    "installs.loc[installs.implicit == False, 'implicit_value'] = 0\n",
    "installs.loc[installs.implicit == True, 'implicit_value'] = 1\n",
    "del installs['implicit']\n",
    "##################### click_hash\n",
    "installs['click_hash'] = installs['click_hash'].astype('category')\n",
    "##################### session_user_agent\n",
    "installs['session_user_agent_value'] = installs['session_user_agent'].cat.codes\n",
    "del installs['session_user_agent']\n",
    "installs.loc[installs.session_user_agent_value == -1, 'session_user_agent_value'] = 0\n",
    "##################### click_hash\n",
    "installs['click_hash_value'] = installs['click_hash'].cat.codes\n",
    "installs.loc[installs.click_hash_value == -1, 'click_hash_value'] = 0\n",
    "del installs['click_hash']\n",
    "##################### user_agent\n",
    "installs['user_agent_value'] = installs['user_agent'].cat.codes\n",
    "installs.loc[installs.user_agent_value == -1, 'user_agent_value'] = 0\n",
    "del installs['user_agent']\n",
    "##################### kind\n",
    "installs['kind_value'] = installs['kind'].cat.codes\n",
    "installs.loc[installs.kind_value == -1, 'kind_value'] = 0\n",
    "del installs['kind']\n",
    "##################### trans_id\n",
    "installs['trans_id_value'] = installs['trans_id'].cat.codes\n",
    "installs.loc[installs.trans_id_value == -1, 'trans_id_value'] = 0\n",
    "del installs['trans_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Ventana 1: Del 18 al 20\n",
    "## Ventana 2: Del 19 al 21\n",
    "## Ventana 3: Del 20 al 22\n",
    "## Ventana 4: Del 21 al 23\n",
    "## Ventana 5: Del 22 al 24\n",
    "################################################################\n",
    "installs_Ventana1 = installs[(installs['dia'] >= 21) & (installs['dia'] <= 23)]\n",
    "installs_Ventana2 = installs[(installs['dia'] >= 24) & (installs['dia'] <= 26)]\n",
    "#installs_Ventana3 = installs[(installs['dia'] >= 20) & (installs['dia'] <= 22)]\n",
    "#installs_Ventana4 = installs[(installs['dia'] >= 21) & (installs['dia'] <= 23)]\n",
    "#installs_Ventana5 = installs[(installs['dia'] >= 22) & (installs['dia'] <= 24)]\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Limpiamos el CSV cargado para que no ocupe memoria.\n",
    "## installs = ''\n",
    "## installs_Ventana1 = ''\n",
    "## installs_Ventana2 = ''\n",
    "## installs_Ventana3 = ''\n",
    "## installs_Ventana4 = ''\n",
    "## installs_Ventana5 = ''\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## AUCTIONS.\n",
    "################################################################\n",
    "## OBTENEMOS TODA LA INFORMACIÓN DE LOS DIFERENTES CSV.\n",
    "auctions = pd.read_csv('../../auctions.csv',nrows=5000000)\n",
    "## TRANSFORMACIÓN DE TIPOS PARA EL CSV (AUCTIONS)\n",
    "auctions['date'] = pd.to_datetime(auctions['date'], infer_datetime_format=True)\n",
    "## DIFERENCIAMOS EN TRES COLUMNAS DIFERENTES EL DIA, MES Y AÑO.\n",
    "auctions['mes'] = auctions['date'].dt.month\n",
    "auctions['dia'] = auctions['date'].dt.day\n",
    "auctions['hora'] = auctions['date'].dt.hour\n",
    "# ARMAMOS UNA LÓGICA PARA SEGMENTAR LAS FRANJAS HORARIAS.\n",
    "# MADRUGADA de 00 a 06\n",
    "auctions['hora_madrugada'] = 0\n",
    "auctions.loc[((auctions.hora > -1) & (auctions.hora < 7)), 'hora_madrugada'] = 1\n",
    "# MAÑANA de 07 a 11\n",
    "auctions['hora_maniana'] = 0\n",
    "auctions.loc[((auctions.hora > 6) & (auctions.hora < 12)), 'hora_maniana'] = 1\n",
    "# ALMUERZO de 12 a 13\n",
    "auctions['hora_almuerzo'] = 0\n",
    "auctions.loc[((auctions.hora > 11) & (auctions.hora < 14)), 'hora_almuerzo'] = 1\n",
    "# TARDE de 14 a 18\n",
    "auctions['hora_tarde'] = 0\n",
    "auctions.loc[((auctions.hora > 13) & (auctions.hora < 19)), 'hora_tarde'] = 1\n",
    "# NOCHE de 19 a 23\n",
    "auctions['hora_noche'] = 0\n",
    "auctions.loc[((auctions.hora > 18) & (auctions.hora < 24)), 'hora_noche'] = 1\n",
    "# RENOMBRAMOS LA COLUMNA PARA LOS JOINS.\n",
    "auctions=auctions.rename(columns = {'device_id':'ref_hash'})\n",
    "auctions=auctions.rename(columns = {'date':'created'})\n",
    "#auctions['cantidad'] = 1\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### date\n",
    "#del auctions['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Ventana 1: Del 18 al 20\n",
    "## Ventana 2: Del 19 al 21\n",
    "## Ventana 3: Del 20 al 22\n",
    "## Ventana 4: Del 21 al 23\n",
    "## Ventana 5: Del 22 al 24\n",
    "################################################################\n",
    "auctions_Ventana1 = auctions[(auctions['dia'] >= 21) & (auctions['dia'] <= 23)]\n",
    "auctions_Ventana2 = auctions[(auctions['dia'] >= 24) & (auctions['dia'] <= 26)]\n",
    "#auctions_Ventana3 = auctions[(auctions['dia'] >= 20) & (auctions['dia'] <= 22)]\n",
    "#auctions_Ventana4 = auctions[(auctions['dia'] >= 20) & (auctions['dia'] <= 23)]\n",
    "#auctions_Ventana5 = auctions[(auctions['dia'] >= 23) & (auctions['dia'] <= 27)]\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## Limpiamos el CSV cargado para que no ocupe memoria.\n",
    "## auctions = ''\n",
    "## auctions_Ventana1 = ''\n",
    "## auctions_Ventana2 = ''\n",
    "## auctions_Ventana3 = ''\n",
    "## auctions_Ventana4 = ''\n",
    "## auctions_Ventana5 = ''\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## TARGET.\n",
    "################################################################\n",
    "## OBTENEMOS TODA LA INFORMACIÓN DE LOS DIFERENTES CSV.\n",
    "targets = pd.read_csv('../../target.csv')\n",
    "targets_sc = targets[targets['ref_hash'].str.contains('_sc')]\n",
    "targets_st = targets[targets['ref_hash'].str.contains('_st')]\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================================================================\n",
    "## JUNTAMOS LOS DATAFRAMES Y EMPEZAMOS A ENTRENAR (SC = INSTALLS).\n",
    "## ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['ref_hash'] = targets['ref_hash'].astype(str)\n",
    "targets_st['ref_hash'] = targets_st['ref_hash'].astype(str)\n",
    "targets_sc['ref_hash'] = targets_sc['ref_hash'].astype(str)\n",
    "installs['ref_hash'] = installs['ref_hash'].astype(str)\n",
    "installs['ref_hash'] = installs['ref_hash'] + '_sc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_Ventana1['ref_hash'] = installs_Ventana1['ref_hash'].astype(str)\n",
    "installs_Ventana1['ref_hash'] = installs_Ventana1['ref_hash'] + '_sc'\n",
    "inst_1 = installs_Ventana1.groupby('ref_hash').min()#.agg(k:np.sum if k == 'cantidad' else k:np.sum for k in installs_Ventana1.columns)\n",
    "installs_Ventana2['ref_hash'] = installs_Ventana2['ref_hash'].astype(str)\n",
    "installs_Ventana2['ref_hash'] = installs_Ventana2['ref_hash'] + '_sc'\n",
    "inst_2 = installs_Ventana2.groupby('ref_hash').min()#.agg(k:np.sum if k == 'cantidad' else k:np.sum for k in installs_Ventana2.columns)\n",
    "inst_1['obj'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_comb = inst_1.merge(inst_2, on=('ref_hash'), suffixes=('_lefto', '_raito'))\n",
    "inst_comb['obj'] = (inst_comb['created_raito'] - inst_comb['created_lefto']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_comb = inst_comb.iloc[:, 0:25]\n",
    "inst_comb['obj'] = inst_comb['obj'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_relevantes_inst = list(inst_comb.select_dtypes(include=['int','float64','uint8']).columns)\n",
    "inst_comb = inst_comb.loc[:, inst_comb.columns.isin(columnas_relevantes_inst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_comb = inst_comb.iloc[:, 7:19]\n",
    "columnas_relevantes_inst = list(inst_2.select_dtypes(include=['int','float64','uint8']).columns)\n",
    "inst_2 = inst_2.loc[:, inst_2.columns.isin(columnas_relevantes_inst)]\n",
    "inst_ventana2 = inst_2.iloc[:, 7:19]\n",
    "target_result_sc = pd.merge(targets_sc, inst_ventana2, how='left', left_on='ref_hash', right_on='ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inst, y_inst = inst_comb.iloc[:,:-1],inst_comb.iloc[:,-1]\n",
    "data_dmatrix_inst = xgb.DMatrix(data=X_inst,label=y_inst)\n",
    "X_train_inst, X_test_inst, y_train_inst, y_test_inst = train_test_split(X_inst, y_inst, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_inst = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, \n",
    "              learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg_inst.fit(X_train_inst,y_train_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_ventana2.columns = [str(col) + '_lefto' for col in inst_ventana2.columns]\n",
    "inst_ventana2['obj'] = 0\n",
    "X_target_inst, y_target_inst = inst_ventana2.iloc[:,:-1],inst_ventana2.iloc[:,-1]\n",
    "preds_sc = xg_reg_inst.predict(X_target_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =================================================================================================\n",
    "## ARMAMOS EN BASE A LA PREDICCIÓN QUE TENEMOS UN CSV PARA SUBIR A KAGGLE CON EL FORMATO INDICADO.\n",
    "## =================================================================================================\n",
    "inst_ventana2 = inst_ventana2.reset_index()\n",
    "submission_sc = pd.DataFrame({ 'resultado': preds_sc, 'ref_hash': inst_ventana2['ref_hash'] })\n",
    "final_sc = pd.merge(targets_sc, submission_sc, how='left', left_on='ref_hash', right_on='ref_hash')\n",
    "final_sc['obj'] = final_sc['resultado']\n",
    "del final_sc['resultado']\n",
    "final_sc.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000169251625791246_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000395625957344683_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003027494996471685_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006670001679961544_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007573308966476713_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1010070503877148763_sc</td>\n",
       "      <td>145693.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1010265377387765028_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1010531372912327058_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1011610998357271358_sc</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1013543838965040946_sc</td>\n",
       "      <td>141122.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ref_hash         obj\n",
       "0  1000169251625791246_sc       0.000\n",
       "1  1000395625957344683_sc       0.000\n",
       "2  1003027494996471685_sc       0.000\n",
       "3  1006670001679961544_sc       0.000\n",
       "4  1007573308966476713_sc       0.000\n",
       "5  1010070503877148763_sc  145693.500\n",
       "6  1010265377387765028_sc       0.000\n",
       "7  1010531372912327058_sc       0.000\n",
       "8  1011610998357271358_sc       0.000\n",
       "9  1013543838965040946_sc  141122.375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================================================================\n",
    "## JUNTAMOS LOS DATAFRAMES Y EMPEZAMOS A ENTRENAR (ST = AUCTIONS).\n",
    "## ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['ref_hash'] = targets['ref_hash'].astype(str)\n",
    "targets_st['ref_hash'] = targets_st['ref_hash'].astype(str)\n",
    "targets_sc['ref_hash'] = targets_sc['ref_hash'].astype(str)\n",
    "auctions['ref_hash'] = auctions['ref_hash'].astype(str)\n",
    "auctions['ref_hash'] = auctions['ref_hash'] + '_st'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_Ventana1['ref_hash'] = auctions_Ventana1['ref_hash'].astype(str)\n",
    "auctions_Ventana1['ref_hash'] = auctions_Ventana1['ref_hash'] + '_st'\n",
    "auct_1 = auctions_Ventana1.groupby('ref_hash').min()\n",
    "auctions_Ventana2['ref_hash'] = auctions_Ventana2['ref_hash'].astype(str)\n",
    "auctions_Ventana2['ref_hash'] = auctions_Ventana2['ref_hash'] + '_st'\n",
    "auct_2 = auctions_Ventana2.groupby('ref_hash').min()\n",
    "auct_1['obj'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_comb = auct_1.merge(auct_2, on=('ref_hash'), suffixes=('_lefto', '_raito'))\n",
    "auct_comb['obj'] = (auct_comb['created_raito'] - auct_comb['created_lefto']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_comb = auct_comb.iloc[:, 0:12]\n",
    "auct_comb['obj'] = auct_comb['obj'].astype(int)\n",
    "columnas_relevantes_auct = list(auct_comb.select_dtypes(include=['int','float64','uint8']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_comb = auct_comb.loc[:, auct_comb.columns.isin(columnas_relevantes_auct)]\n",
    "auct_comb = auct_comb.iloc[:, 2:12]\n",
    "columnas_relevantes_auct = list(auct_2.select_dtypes(include=['int','float64','uint8']).columns)\n",
    "auct_2 = auct_2.loc[:, auct_2.columns.isin(columnas_relevantes_auct)]\n",
    "auct_ventana2 = auct_2.iloc[:, 2:12]\n",
    "target_result_st = pd.merge(targets_st, auct_ventana2, how='left', left_on='ref_hash', right_on='ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_auct, y_auct = auct_comb.iloc[:,:-1],auct_comb.iloc[:,-1]\n",
    "data_dmatrix_auct = xgb.DMatrix(data=X_auct,label=y_auct)\n",
    "X_train_auct, X_test_auct, y_train_auct, y_test_auct = train_test_split(X_auct, y_auct, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_auct = xgb.XGBRegressor(objective = 'reg:linear', colsample_bytree = 0.3, \n",
    "         learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg_auct.fit(X_train_auct,y_train_auct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_ventana2.columns = [str(col) + '_lefto' for col in auct_ventana2.columns]\n",
    "auct_ventana2['obj'] = 0\n",
    "X_target_auct, y_target_auct = auct_ventana2.iloc[:,:-1],auct_ventana2.iloc[:,-1]\n",
    "preds_st = xg_reg_auct.predict(X_target_auct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =================================================================================================\n",
    "## ARMAMOS EN BASE A LA PREDICCIÓN QUE TENEMOS UN CSV PARA SUBIR A KAGGLE CON EL FORMATO INDICADO.\n",
    "## =================================================================================================\n",
    "auct_ventana2 = auct_ventana2.reset_index()\n",
    "submission_st = pd.DataFrame({ 'resultado': preds_st, 'ref_hash': auct_ventana2['ref_hash'] })\n",
    "final_st = pd.merge(targets_st, submission_st, how='left', left_on='ref_hash', right_on='ref_hash')\n",
    "final_st['obj'] = final_st['resultado']\n",
    "del final_st['resultado']\n",
    "final_st.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000169251625791246_st</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000395625957344683_st</td>\n",
       "      <td>101929.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003027494996471685_st</td>\n",
       "      <td>140999.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006670001679961544_st</td>\n",
       "      <td>105994.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007573308966476713_st</td>\n",
       "      <td>147762.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1010070503877148763_st</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1010265377387765028_st</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1010531372912327058_st</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1011610998357271358_st</td>\n",
       "      <td>150649.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1013543838965040946_st</td>\n",
       "      <td>148993.546875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ref_hash            obj\n",
       "0  1000169251625791246_st       0.000000\n",
       "1  1000395625957344683_st  101929.500000\n",
       "2  1003027494996471685_st  140999.015625\n",
       "3  1006670001679961544_st  105994.859375\n",
       "4  1007573308966476713_st  147762.187500\n",
       "5  1010070503877148763_st       0.000000\n",
       "6  1010265377387765028_st       0.000000\n",
       "7  1010531372912327058_st       0.000000\n",
       "8  1011610998357271358_st  150649.781250\n",
       "9  1013543838965040946_st  148993.546875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_st.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [final_sc, final_st]\n",
    "final = pd.concat(frames)\n",
    "final.to_csv(\"submission_grupo34_003.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======================================================================\n",
    "### ======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 23320397813996.765625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======================================================================\n",
    "### ======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = installs.groupby('ref_hash').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks['ref_hash'] = clicks['ref_hash'].astype(str)\n",
    "clicks['ref_hash'] = clicks['ref_hash'] + '_sc'\n",
    "auctions['ref_hash'] = auctions['ref_hash'].astype(str)\n",
    "auctions['ref_hash'] = auctions['ref_hash'] + '_sc'\n",
    "events['ref_hash'] = events['ref_hash'].astype(str)\n",
    "events['ref_hash'] = events['ref_hash'] + '_sc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_clicks = clicks.merge(targets, on=('ref_hash'), suffixes=('_l', '_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_auctions = auctions.merge(targets, on=('ref_hash'), suffixes=('_l', '_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_events = events.merge(targets, on=('ref_hash'), suffixes=('_l', '_r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======================================================================\n",
    "### ======================================================================\n",
    "### ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasamos la columna a predecir a la última posición para facilitar el trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna_dia = auctions.pop('dia')\n",
    "auctions['dia'] = columna_dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = auctions.iloc[:,:-1],auctions.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertimos los datos a DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hiper-parámetros\n",
    "\n",
    "    learning_rate: tasa de aprendizaje\n",
    "    max_depth: máxima profundidad de cada árbol\n",
    "    subsample: porcentaje de muestras usadas para cada árbol (valor muy bajo, posible underfitting)\n",
    "    colsample_bytree: porcentaje de features usadas para cada árbol (valores muy alto, posible overfitting)\n",
    "    n_estimators: cantidad de árboles a construir.\n",
    "    objective: función de error a utilizar (algunas: reg:linear para regresión, reg:logistic o binary:logistic para clasificación)\n",
    "\n",
    "### Parámetros de regularización:\n",
    "\n",
    "    gamma: umbral para hacer split basado en la reducción de error de hacer el nuevo split.\n",
    "    alpha: regularización para los pesos de las hojas. Un valor más alto genera una mayor regularización.\n",
    "    lambda: similar alpha pero para la sintonia fina.\n",
    "\n",
    "### Creamos set de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciamos el regresor de XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos el error en las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 7.808578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
